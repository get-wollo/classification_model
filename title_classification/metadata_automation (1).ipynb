{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"XC4XrYqcSxD7","executionInfo":{"status":"ok","timestamp":1672241483595,"user_tz":0,"elapsed":16550,"user":{"displayName":"Patrick Higgins","userId":"06954263998622328275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"08d49487-d6a7-4ec7-9737-c19f8bd1dbb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ipdb in /usr/local/lib/python3.8/dist-packages (0.13.11)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.8/dist-packages (from ipdb) (2.0.1)\n","Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.8/dist-packages (from ipdb) (8.7.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipdb) (4.4.2)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (4.8.0)\n","Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n","Requirement already satisfied: stack-data in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (0.6.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (0.18.2)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (3.0.36)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n","Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (2.6.1)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/dist-packages (from ipython>=7.31.1->ipdb) (0.1.6)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=7.31.1->ipdb) (0.2.5)\n","Requirement already satisfied: pure-eval in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=7.31.1->ipdb) (0.2.2)\n","Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=7.31.1->ipdb) (2.2.1)\n","Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=7.31.1->ipdb) (1.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=7.31.1->ipdb) (1.15.0)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]}],"source":["\n","!pip install ipdb\n","import json\n","import os\n","import re\n","import pandas as pd\n","from google.colab import drive\n","import nltk\n","import string\n","from nltk.tokenize import word_tokenize \n","import re\n","from nltk.tokenize.treebank import TreebankWordDetokenizer\n","from nltk.corpus import stopwords\n","from spacy.lang.en import English\n","import spacy\n","from collections import Counter\n","import ipdb\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"9FEIqcSATLdE","executionInfo":{"status":"ok","timestamp":1672241485546,"user_tz":0,"elapsed":1957,"user":{"displayName":"Patrick Higgins","userId":"06954263998622328275"}}},"outputs":[],"source":["%%capture\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"p4686-5vTCdM","executionInfo":{"status":"ok","timestamp":1672241485547,"user_tz":0,"elapsed":7,"user":{"displayName":"Patrick Higgins","userId":"06954263998622328275"}}},"outputs":[],"source":["path = f'/content/drive/MyDrive/ai_project/dataset_processing/datasets_amazon_cleaned/'\n","metadata_path = f'/content/drive/MyDrive/ai_project/dataset_processing/cleaned_big_metadata/'"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4xS4sIYZc6qL","executionInfo":{"status":"ok","timestamp":1672241485547,"user_tz":0,"elapsed":6,"user":{"displayName":"Patrick Higgins","userId":"06954263998622328275"}}},"outputs":[],"source":["# Define Tokenisation functions\n","\n","# Run regex commands to parse the 'title' entries into lists without:\n","# numbers\n","# html tags\n","# whitespace\n","# punctuation\n","\n","def remove_span_tags(text):\n","   \n","    clean = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n","    return re.sub(clean,'',text)\n","    \n","def remove_html_tags(text):\n","    \"\"\"Remove html tags from a string\"\"\"\n","    \n","    clean = re.compile('<.*?>')\n","    return re.sub(clean, '', text)\n","def remove_numbers_with_letters(text): \n","    '''  \n","    This function takes strings containing numbers and returns strings with numbers removed.\n","    '''\n","    text = re.sub(r'\\d+\\w+\\d+','',text)\n","    text = re.sub(r'\\d+\\w+','',text)\n","    text = re.sub(r'\\d+','',text)\n","    \n","    return text    \n","    #this is may need to changed according to which numbers are useful for classification\n","    \n","def remove_whitespace(text): \n","    '''\n","    This function takes strings containing mentions and returns strings with \n","    whitespaces removed.\n","    '''\n","    \n","    return \" \".join(text.split())\n","def remove_punctuation(text): \n","    \"\"\"\n","    This function takes strings containing self defined punctuations and returns\n","    strings with punctuations removed.\n","    \"\"\"\n","    translator = str.maketrans('', '', string.punctuation) \n","    return text.translate(translator) \n","\n","def remove_stopwords(tokenized_text): \n","    '''\n","    This function takes a list of tokenized words from the description and title, removes self-defined stop words from the list,\n","    and returns the list of words with stop words removed\n","    '''\n","    try: \n","      filtered_text = [word for word in tokenized_text if word not in stopwords_list] \n","    except:\n","      filtered_text = []\n","    return filtered_text"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"9PFClBSBc7vO","executionInfo":{"status":"ok","timestamp":1672242452998,"user_tz":0,"elapsed":908,"user":{"displayName":"Patrick Higgins","userId":"06954263998622328275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ad03387b-8bce-4394-bc79-582916f9f52e"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["nltk.download('punkt')\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","\n","def tokenize_sent(text): \n","  word_tokens = word_tokenize(text)  \n","  return word_tokens \n","\n","\n","def tokenize_and_lemmatize(series): \n","  empty_list = []\n","  for doc in nlp.pipe(series, batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]):\n","    next_item = [tok.lemma_ for tok in doc if not tok.lemma_.isspace()]\n","    empty_list.append(next_item)\n","\n","  return empty_list \n","\n","\n","def detokenize_sent(text): \n","    ''' \n","    This function takes a list of words and returns a string.\n","    '''\n","    if type(text) == list:\n","      word_detokens = TreebankWordDetokenizer().detokenize(text)\n","    else:\n","      word_detokens = ''\n","\n","\n","      \n","    return word_detokens\n"]},{"cell_type":"markdown","metadata":{"id":"W50cQ2KMEz0k"},"source":["#### *Pipes to 1 csv file*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4179D2ubUEeC","executionInfo":{"status":"aborted","timestamp":1672240453386,"user_tz":0,"elapsed":8,"user":{"displayName":"Patrick Higgins","userId":"06954263998622328275"}}},"outputs":[],"source":["# data_set = pd.DataFrame()\n","\n","# for file in os.listdir(metadata_path):\n","#   if file[-4:] == '.csv':\n","#     print(f'\\rProcessing {file}',end='')\n","#     file_name = file.split('.')[0]\n","#     df = pd.read_csv(f'{metadata_path}{file}')\n","#     cont = True\n","#     \"\"\"try: \n","#       t = df[df['category'].map(bool)].reset_index(drop=True)\n","#       if len(t) > 25000 and cont: df, cont = t, False\n","#     except: \n","#       print('Had no categories')\"\"\"\n","\n","#     # Gives the dataframe a new attribute \"main_cat\" using the file name \n","#     df['main_cat'] = file_name\n","\n","#     # Checks there's a valid title: Not NaN or longer than 200 characters\n","#     try:\n","#       df = df.dropna(subset=['title'])\n","#       df = df[df['title'].apply(lambda x : len(x) < 200)]\n","    \n","#       # Drops row if the Price column is NaN\n","#       t = df.dropna(subset=['price'])\n","#       # Checks remaining dataframe is bigger than 25k rows\n","#       if len(t) > 25000 and cont: df, cont = t, False\n","#     except:\n","#       print(f'\\rProblem with {file}')\n","    \n","#     data_set = data_set.append(df)\n","# data_set = data_set.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"sFBE_I_dFxOB"},"source":["#### *Processes each metadata csv into a slimmed 25k csv*"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYgE_AiaE6WS","outputId":"505dd64d-0220-4d7d-c725-6e66c9e57543","executionInfo":{"status":"ok","timestamp":1672248799256,"user_tz":0,"elapsed":5562367,"user":{"displayName":"Patrick Higgins","userId":"06954263998622328275"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Video_Games.csv has less than 25000 rows\n","Software.csv has less than 25000 rows\n","Prime_Pantry.csv has less than 25000 rows\n","Movies_and_TV.csv has less than 25000 rows\n","Magazine_Subscriptions.csv has less than 25000 rows\n","Luxury_Beauty.csv has less than 25000 rows\n","Gift_Cards.csv has less than 25000 rows\n","Digital_Music.csv has less than 25000 rows\n","Books.csv has less than 25000 rows\n","Applicances.csv has less than 25000 rows\n","Amazon_Fashion.csv has less than 25000 rows\n","All_Beauty.csv has less than 25000 rows\n"]}],"source":["data_set = pd.DataFrame()\n","\n","output_path = f'/content/drive/MyDrive/ai_project/dataset_processing/datasets_amazon_cleaned/all_metadata_files_upto25k/'\n","\n","for file in os.listdir(metadata_path):\n","  if file[-4:] == '.csv':\n","    print(f'\\rProcessing {file}',end='')\n","    file_name = file.split('.')[0]\n","    df = pd.read_csv(f'{metadata_path}{file}')\n","\n","    # Gives the dataframe a new attribute \"main_cat\" using the file name \n","    # try:\n","    df['main_cat'] = file_name\n","\n","        # dropping NaNs\n","    df = df.dropna(axis = 0 )\n","        # Getting rid of empty imageURLs\n","    df = df[df['imageURL'].apply(lambda x: len(x) > 3)]\n","      \n","        # Getting rid of excessively long titles\n","    df = df[df['title'].apply(lambda x: len(x) < 250)]\n","\n","        #getting rid of excessively long prices\n","\n","    df = df[df['price'].apply(lambda x: len(x) <= 8)]\n","\n","  \n","        #cleaning title\n","    df[\"cleaned_title\"] = df[\"title\"].apply(lambda x: remove_html_tags(str(x)))\n","    df[\"cleaned_title\"] = df[\"cleaned_title\"].apply(lambda x: str(x).lower())\n","    df[\"cleaned_title\"] = df[\"cleaned_title\"].apply(lambda x: remove_whitespace(str(x))).apply(lambda x: remove_punctuation(str(x))).apply(lambda x: remove_numbers_with_letters(str(x)))\n","    df[\"cleaned_title\"] = df[\"cleaned_title\"].apply(lambda x: remove_html_tags(str(x)))\n","    df[\"cleaned_title\"] = df[\"cleaned_title\"].apply(lambda x: remove_span_tags(str(x)))\n","      # converting to lowercase\n","    df[\"cleaned_title\"] = df[\"cleaned_title\"].apply(lambda x: str(x).lower())\n","       #tokenizing the title\n","    df[\"title_token\"] = df[\"cleaned_title\"].apply(word_tokenize)\n","        #searching for stopwords\n","      \n","    counter = Counter()\n","    for word in  [w for sent in df[\"title_token\"] for w in sent]:\n","       counter[word] += 1        \n","    counter.most_common(15)\n","    top_n = 10\n","    stopwords_list = set([word for (word, count) in counter.most_common(top_n)])\n","    #removing the stopwords \n","\n","    df[\"title_stopwords\"] = df[\"title_token\"].apply(remove_stopwords)\n","    df[\"title_stopwords\"] = df[\"title_stopwords\"].apply(detokenize_sent)\n","\n","    thelist = tokenize_and_lemmatize(df['cleaned_title'].to_list())\n","    df = df.assign(title_lemmatize_tokens = thelist)\n","    \n","    df[\"title_lemmatize\"] = df[\"title_lemmatize_tokens\"].apply(detokenize_sent)\n","\n","\n","    df[\"title_stopwords_lemmatize_tokens\"] = df[\"title_lemmatize_tokens\"].apply(remove_stopwords)\n","    df[\"title_stopwords_lemmatize\"] = df[\"title_stopwords_lemmatize_tokens\"].apply(detokenize_sent)\n","   \n","    \n","\n","       # dropping any strange titles which didn't format properly\n","    df = df.dropna()\n","    df = df.reset_index(drop=True)\n","        # Removes empty titles after cleaning for stopwords\n","    df = df.iloc[list(df[~(df[\"title_stopwords\"].apply(lambda x : len(x)) == 0)].index)]\n","        #reseting the index\n","        \n","      # Shuffling the rows \n","    df = df.sample(frac = 1)\n","    data_ready = df\n","\n","  \n","    try:\n","      df = data_ready.sample(25000)\n","      df = df.reset_index(drop=True)\n","    except:\n","      print(f'\\r{file} has less than 25000 rows')\n","    df.reset_index(drop=True).to_csv(f'{output_path}{file}',index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7Z13av-dzjo","executionInfo":{"status":"aborted","timestamp":1672240453387,"user_tz":0,"elapsed":9,"user":{"displayName":"Patrick Higgins","userId":"06954263998622328275"}}},"outputs":[],"source":[" "]}],"metadata":{"colab":{"collapsed_sections":["W50cQ2KMEz0k"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}